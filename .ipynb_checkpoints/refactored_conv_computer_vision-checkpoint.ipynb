{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce273e29-8a43-445a-b36a-e1d2983bad42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amittomar/miniconda3/envs/denv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch version :1.13.1\n",
      " torchvision version : 0.14.1\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\" torch version :{torch.__version__}\")\n",
    "print(f\" torchvision version : {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83d6eb-dda3-41d6-86d9-5f1379b96337",
   "metadata": {},
   "source": [
    "## Load data and load train and test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5250916c-0f6f-4a29-9d26-24cac63250e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(root=\"data\",\n",
    "                                  train=True,\n",
    "                                  download=True,\n",
    "                                  transform=torchvision.transforms.ToTensor(), # How do we transform the data\n",
    "                                  target_transform=None)  # How do you transofrm the labels\n",
    "\n",
    "test_data = datasets.FashionMNIST(root=\"data\",\n",
    "                                  train=False,\n",
    "                                  download=True,\n",
    "                                  transform=torchvision.transforms.ToTensor(), # How do we transform the data\n",
    "                                  target_transform=None)  # How do you transofrm the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5f93ae-7fe7-4b74-9132-19051d89aab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6ab348-3584-4ea7-a09f-d49d08c2a87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88250d23-0889-478f-b813-b66fa400e0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'T-shirt/top',\n",
       " 1: 'Trouser',\n",
       " 2: 'Pullover',\n",
       " 3: 'Dress',\n",
       " 4: 'Coat',\n",
       " 5: 'Sandal',\n",
       " 6: 'Shirt',\n",
       " 7: 'Sneaker',\n",
       " 8: 'Bag',\n",
       " 9: 'Ankle boot'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.class_to_idx\n",
    "id_to_class = {}\n",
    "for idx,clas in enumerate(class_names):\n",
    "    id_to_class[idx]= clas\n",
    "id_to_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba4c1d-99fb-433a-a8bd-52031001a57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7feb5882-94d9-4775-843b-ddc952118767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x12c5e6bc0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x12c5e73a0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# not shuffling the test data\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False )\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3459c-af62-484c-81ff-9282722c4cf5",
   "metadata": {},
   "source": [
    "## Create Model with linear and Non Liner layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2dfc145-99e0-49cb-89b3-c609e35d7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistModelV1(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_shape: int,\n",
    "                hidden_unit: int,\n",
    "                output_shape:int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=input_shape, out_features=hidden_unit),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=hidden_unit,\n",
    "                 out_features= output_shape),\n",
    "        nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f101bd-d2b8-4000-8b4a-174aa4c2287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create manual instance pf MOdel_1\n",
    "torch.manual_seed(42)\n",
    "model_1 = FashionMnistModelV1(input_shape=784,\n",
    "                             hidden_unit=10,\n",
    "                             output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c074ef-3dd0-4f12-8ccc-3220b9fd82c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x12c583610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ca0da-31c2-4adb-8979-58ecda898f50",
   "metadata": {},
   "source": [
    "## Set loss fun and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1267bf-b0c2-41cf-8e6e-fba017b992c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43574733-2652-4505-bff9-0c496eb5e87d",
   "metadata": {},
   "source": [
    "## Functioning Training and testing Step in shape of different reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4b4e7f-f108-4056-aaa0-13b1cfaf4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn : torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "             device: torch.device = device) :\n",
    "    \"\"\" Returns a dictionary containing the results of model predicting on data loader\"\"\"\n",
    "    loss, acc = 0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(data_loader):\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            # Make ored\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Acumulate teh loss and accuracy\n",
    "            \n",
    "            loss += loss_fn(y_pred,y)\n",
    "            acc += accuracy_fn(y_true =y, y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # normalize loss and acc by getting mean of batch for loss/acc\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    print(f\"Test loss: {loss:3f} | Test acc : {acc:2f}% \\n\")\n",
    "    return{ \"model_name\" : model.__class__.__name__,\n",
    "               \"model_loss\" : loss.item(),\n",
    "               \"model_acc\" : acc\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "480ec29a-b0cc-417d-b568-868a04c5124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "def train_step(model : torch.nn.Module,\n",
    "               dataloader : torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"Performs a training with model trying to learn on dataloader\"\"\"\n",
    "    train_loss, train_acc = 0,0\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        model.train()\n",
    "        #1, Fwd pass\n",
    "        y_pred = model(X)\n",
    "        #2. loss\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        train_loss += loss\n",
    "\n",
    "        train_acc += accuracy_fn(y_true=y,y_pred=y_pred.argmax(dim=1))\n",
    "        # 3. \n",
    "        optimizer.zero_grad()\n",
    "        # 4. loss back\n",
    "        loss.backward()\n",
    "        # 5 . Step\n",
    "        optimizer.step()\n",
    "        # print\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/ {len(dataloader.dataset)} samples\")\n",
    "\n",
    "        # normalize loss and acc by getting mean of batch for loss/acc\n",
    "        train_loss /= len(dataloader)\n",
    "        train_acc /= len(dataloader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:3f} | Train acc : {train_acc:2f}% \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336d62fc-6234-4870-ad73-7bcb8eabbbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/amittomar/miniconda3/envs/denv/lib/python3.10/site-packages (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f13580-2512-472e-812d-c3f166579d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_total_time(start: float,\n",
    "       end: float,\n",
    "       device: torch.device = None):\n",
    "    tat = end - start\n",
    "    print(f\"Train time on :{device} : {tat:3f} seconds\")\n",
    "    return tat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3a56d69-95af-465d-bd30-df6465b0116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      " **************\n",
      "Looked at 0/ 60000 samples\n",
      "Looked at 12800/ 60000 samples\n",
      "Looked at 25600/ 60000 samples\n",
      "Looked at 38400/ 60000 samples\n",
      "Looked at 51200/ 60000 samples\n",
      "Train loss: 0.000480 | Train acc : 0.035020% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 313/313 [00:00<00:00, 1687.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.954342 | Test acc : 65.565096% \n",
      "\n",
      "{'model_name': 'FashionMnistModelV1', 'model_loss': 0.9543418288230896, 'model_acc': 65.56509584664536}\n",
      "Epoch: 1 \n",
      " **************\n",
      "Looked at 0/ 60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 12800/ 60000 samples\n",
      "Looked at 25600/ 60000 samples\n",
      "Looked at 38400/ 60000 samples\n",
      "Looked at 51200/ 60000 samples\n",
      "Train loss: 0.000354 | Train acc : 0.038354% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 313/313 [00:00<00:00, 1710.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.922483 | Test acc : 66.244010% \n",
      "\n",
      "{'model_name': 'FashionMnistModelV1', 'model_loss': 0.9224833250045776, 'model_acc': 66.24400958466454}\n",
      "Epoch: 2 \n",
      " **************\n",
      "Looked at 0/ 60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 12800/ 60000 samples\n",
      "Looked at 25600/ 60000 samples\n",
      "Looked at 38400/ 60000 samples\n",
      "Looked at 51200/ 60000 samples\n",
      "Train loss: 0.000639 | Train acc : 0.028356% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 313/313 [00:00<00:00, 1720.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.903419 | Test acc : 66.813099% \n",
      "\n",
      "{'model_name': 'FashionMnistModelV1', 'model_loss': 0.9034186005592346, 'model_acc': 66.81309904153355}\n",
      "Train time on :cpu : 5.403859 seconds\n",
      "time in training : 5.403859124984592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "from tqdm import tqdm\n",
    "# measure time\n",
    "from timeit import default_timer as timer\n",
    "training_start_time = timer()\n",
    "\n",
    "epochs =3\n",
    "\n",
    "# Create a training toop \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch} \\n **************\")\n",
    "    train_step(model=model_1,\n",
    "              dataloader=train_dataloader,\n",
    "              loss_fn= loss_fn,\n",
    "              optimizer=optimizer,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device= device)\n",
    "    test_ret = test_step(model= model_1,\n",
    "             data_loader=test_dataloader,\n",
    "             accuracy_fn=accuracy_fn,\n",
    "            loss_fn=loss_fn,\n",
    "             device=device)\n",
    "    print(test_ret)\n",
    "train_time_end = timer()\n",
    "tat = print_total_time(start=training_start_time,\n",
    "         end=train_time_end,\n",
    "         device= device)\n",
    "print(f\"time in training : {tat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe51184-b53a-4d56-b80a-25787106f196",
   "metadata": {},
   "source": [
    "## Article on utilizing GPu to fast speed\n",
    "##### https://horace.io/brrr_intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126efaa0-f92b-49ae-a2c7-49437ff8aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get model results decitionary\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn : torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device = device) :\n",
    "    \"\"\" Returns a dictionary containing the results of model predicting on data loader\"\"\"\n",
    "    loss, acc = 0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(data_loader):\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            # Make ored\n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # Acumulate teh loss and accuracy\n",
    "            \n",
    "            loss += loss_fn(y_pred,y)\n",
    "            acc += accuracy_fn(y_true =y, y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        return{ \"model_name\" : model.__class__.__name__,\n",
    "               \"model_loss\" : loss.item(),\n",
    "               \"model_acc\" : acc\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d16c4d4-9ed8-4d5f-a8f5-f84a6c4eb749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 313/313 [00:00<00:00, 1699.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMnistModelV1',\n",
       " 'model_loss': 0.9034186005592346,\n",
       " 'model_acc': 66.81309904153355}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = eval_model(model=model_1,\n",
    "                            data_loader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                           accuracy_fn=accuracy_fn,\n",
    "                           device = device)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6e0c4-bd65-446e-a94c-234eeed8ea4b",
   "metadata": {},
   "source": [
    "### Model expirements\n",
    "##### Use of ConvNet  in visual Data  : https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ca2bfb7-8722-4384-9119-f7d7404e8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class FashionMnistModelV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_shape: int,\n",
    "                hidden_units: int,\n",
    "                output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=input_shape,\n",
    "                 out_channels= hidden_units,\n",
    "                 kernel_size= 3,\n",
    "                 stride= 1,\n",
    "                 padding= 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = hidden_units,\n",
    "                 out_channels = hidden_units,\n",
    "                 kernel_size  = 3,\n",
    "                 stride=1,\n",
    "                 padding=1),  # Value we set ourself are hyper parameter\n",
    "        nn.MaxPool2d(kernel_size=2))\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= hidden_units,\n",
    "                                         out_channels= hidden_units, \n",
    "                                         kernel_size= 3,\n",
    "                                         stride =1 ,\n",
    "                                         padding =1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels= hidden_units,\n",
    "                     out_channels= hidden_units,\n",
    "                     kernel_size =3,\n",
    "                     stride=1,\n",
    "                     padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.classification_layer = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7,\n",
    "                     out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # return self.classification_layer(self.conv_block_2(self.conv_block_1(x)))\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(f\"shape post 1st conv layer : {x.shape}\")\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(f\"shape post 2nd conv layer : {x.shape}\")\n",
    "        x = self.classification_layer(x)\n",
    "        # print(f\"shape post classification layer : {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00b4de-f5cc-4a43-a544-1ece57e4f378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4d1add-2f4e-4575-847b-f22e655caf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMnistModelV2(input_shape=1,\n",
    "                             hidden_units=10,\n",
    "                             output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2aff6-afac-4293-8e75-5cd85ce60374",
   "metadata": {},
   "source": [
    "## steping through nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d6ffed7-3807-4209-8f7b-fab01b5209fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "images = torch.randn(size=(32,3,64,64))\n",
    "test_image = images[0]\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e9c55e-1517-47f0-a2dd-976afe411551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create conv2d layer\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                      kernel_size=(3,3),\n",
    "                      stride=1,\n",
    "                      padding=1)\n",
    "conv_out = conv_layer(test_image)\n",
    "conv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f603feb-4121-4607-bae8-3dc9e6f0edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image shape: torch.Size([3, 64, 64]) \n",
      "Test image with unsqueeze: torch.Size([1, 3, 64, 64]) \n",
      "Test image conved : torch.Size([1, 10, 64, 64]) \n"
     ]
    }
   ],
   "source": [
    "##stepping through nn.MaxPoool\n",
    "print(f\"Test image shape: {test_image.shape} \")\n",
    "print(f\"Test image with unsqueeze: {test_image.unsqueeze(0).shape} \")\n",
    "\n",
    "max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# pass data through conv_layer\n",
    "test_conv_out = conv_layer(test_image.unsqueeze(dim=0))\n",
    "print(f\"Test image conved : {test_conv_out.shape} \")\n",
    "\n",
    "#pass data through Maxpool layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ace6b561-3269-482c-800b-f371b1b7f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# create a random tendsor with similar no of dimensions\n",
    "random_tensor = torch.randn(1,1,2,2)\n",
    "random_tensor\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "max_pooled_tensor = max_pool_layer(random_tensor)\n",
    "max_pooled_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6b01dc8-e42c-4901-980a-f5afe487b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = FashionMnistModelV2(input_shape=1,\n",
    "                            hidden_units=8,\n",
    "                             output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eed55c27-d85e-463d-a11a-a017edaeb0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image,label = train_data[0]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81f18564-11ce-488b-b451-f22391e4b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image post Unsqueezee  : torch.Size([1, 1, 28, 28])\n",
      "Image size post conv : torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "image = image.unsqueeze(dim=0)\n",
    "print(f\"Image post Unsqueezee  : {image.shape}\")\n",
    "res = model_3(image)\n",
    "print(f\"Image size post conv : {res.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed2288-71e4-4b60-b1fa-5e609160cd89",
   "metadata": {},
   "source": [
    "### Setup loss_fn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01417872-ab94-425d-9cc4-6bdc74c56426",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup loss_fn and optimizer\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_3.parameters(), \n",
    "                            lr= 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f8b90-1b53-42ff-adb5-02f4b74f1e8a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0761ef99-66f7-4ce3-92da-fc296870493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                    | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0*************\n",
      "\n",
      "Looked at 0/ 60000 samples\n",
      "Looked at 12800/ 60000 samples\n",
      "Looked at 25600/ 60000 samples\n",
      "Looked at 38400/ 60000 samples\n",
      "Looked at 51200/ 60000 samples\n",
      "Train loss: 0.001229 | Train acc : 0.006668% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                  | 0/313 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|██████▉                                                 | 39/313 [00:00<00:00, 385.02it/s]\u001b[A\n",
      " 26%|██████████████▎                                         | 80/313 [00:00<00:00, 396.62it/s]\u001b[A\n",
      " 39%|█████████████████████▎                                 | 121/313 [00:00<00:00, 402.37it/s]\u001b[A\n",
      " 52%|████████████████████████████▍                          | 162/313 [00:00<00:00, 404.50it/s]\u001b[A\n",
      " 65%|███████████████████████████████████▋                   | 203/313 [00:00<00:00, 405.62it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████▉            | 244/313 [00:00<00:00, 405.73it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████| 313/313 [00:00<00:00, 404.18it/s]\u001b[A\n",
      " 33%|████████████████████                                        | 1/3 [00:22<00:45, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.302711 | Test acc : 9.994010% \n",
      "\n",
      "Epoch : 1*************\n",
      "\n",
      "Looked at 0/ 60000 samples\n",
      "Looked at 12800/ 60000 samples\n",
      "Looked at 25600/ 60000 samples\n",
      "Looked at 38400/ 60000 samples\n",
      "Looked at 51200/ 60000 samples\n",
      "Train loss: 0.001228 | Train acc : 0.003335% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                  | 0/313 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|███████▎                                                | 41/313 [00:00<00:00, 401.30it/s]\u001b[A\n",
      " 27%|██████████████▊                                         | 83/313 [00:00<00:00, 407.07it/s]\u001b[A\n",
      " 40%|█████████████████████▊                                 | 124/313 [00:00<00:00, 406.80it/s]\u001b[A\n",
      " 53%|████████████████████████████▉                          | 165/313 [00:00<00:00, 407.21it/s]\u001b[A\n",
      " 66%|████████████████████████████████████▎                  | 207/313 [00:00<00:00, 409.41it/s]\u001b[A\n",
      " 80%|███████████████████████████████████████████▊           | 249/313 [00:00<00:00, 410.74it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████| 313/313 [00:00<00:00, 408.79it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████                    | 2/3 [00:45<00:22, 22.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.302711 | Test acc : 9.994010% \n",
      "\n",
      "Epoch : 2*************\n",
      "\n",
      "Looked at 0/ 60000 samples\n",
      "Looked at 12800/ 60000 samples\n",
      "Looked at 25600/ 60000 samples\n",
      "Looked at 38400/ 60000 samples\n",
      "Looked at 51200/ 60000 samples\n",
      "Train loss: 0.001233 | Train acc : 0.003335% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                  | 0/313 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|███████▎                                                | 41/313 [00:00<00:00, 406.12it/s]\u001b[A\n",
      " 26%|██████████████▋                                         | 82/313 [00:00<00:00, 405.44it/s]\u001b[A\n",
      " 39%|█████████████████████▌                                 | 123/313 [00:00<00:00, 406.28it/s]\u001b[A\n",
      " 52%|████████████████████████████▊                          | 164/313 [00:00<00:00, 401.38it/s]\u001b[A\n",
      " 65%|████████████████████████████████████                   | 205/313 [00:00<00:00, 403.62it/s]\u001b[A\n",
      " 79%|███████████████████████████████████████████▍           | 247/313 [00:00<00:00, 406.20it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████| 313/313 [00:00<00:00, 406.51it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████| 3/3 [01:08<00:00, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.302711 | Test acc : 9.994010% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch : {epoch}*************\\n\")\n",
    "    train_step(model=model_3,\n",
    "              dataloader=train_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              optimizer=optimizer,\n",
    "              device=device)\n",
    "    test_step(model=model_3,\n",
    "             data_loader=test_dataloader,\n",
    "             loss_fn=loss_fn,\n",
    "             accuracy_fn = accuracy_fn,\n",
    "             device= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea53d424-b7c3-4959-8b57-bf7545e358b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 313/313 [00:00<00:00, 399.81it/s]\n"
     ]
    }
   ],
   "source": [
    "model_2_results = eval_model(model=model_2,\n",
    "                            data_loader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            accuracy_fn=accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5f04f2c-4389-42f3-ab0b-ee3d22af8d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMnistModelV2',\n",
       " 'model_loss': 2.302710771560669,\n",
       " 'model_acc': 9.994009584664537}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b789394-6403-4a9a-b8bb-2c3d62c8467c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <td>FashionMnistModelV1</td>\n",
       "      <td>0.903419</td>\n",
       "      <td>66.813099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_loss</th>\n",
       "      <td>FashionMnistModelV1</td>\n",
       "      <td>0.903419</td>\n",
       "      <td>66.813099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_acc</th>\n",
       "      <td>FashionMnistModelV1</td>\n",
       "      <td>0.903419</td>\n",
       "      <td>66.813099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  model_loss  model_acc\n",
       "model_name  FashionMnistModelV1    0.903419  66.813099\n",
       "model_loss  FashionMnistModelV1    0.903419  66.813099\n",
       "model_acc   FashionMnistModelV1    0.903419  66.813099"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "compare_results = pd.DataFrame(model_1_results, \n",
    "                               model_2_results)\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954aef43-8ced-4075-ad5a-4b97d9ab695c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae03566-6856-46bb-9d2e-7c01054e543e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce554ac8-8ce1-4c7c-92e2-a971559ea43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59514ffc-b0ea-4af4-9ceb-c0b2e34472ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a16001-5ea5-43f7-9c26-c966f8fd53df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b715f-c42c-4b6e-8a5c-b5e3e5e6ef2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaad78f-1038-4c1c-9d04-da7b07bde447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3defeb9-8908-4694-a357-9850548d86a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1b2b6-f1cc-49c9-85d8-ff33c525eb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22101995-55e3-418d-95d9-a921fb629fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72e324-f7bd-479e-a2c6-5a98959eb2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138f74a-b5fe-4f4c-a79b-df7c22c34f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c79b9d-f828-4c0d-8c85-a6d187e71e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8bd54-8636-4d5c-abcc-18e21dc05795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762e890-44ec-47c7-8ea2-2c2038e35f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42bac016-4b80-41a3-b385-64625af5e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268190da-0248-452f-8355-0d9e14fcba25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf437a-7ae6-4469-94bc-707342dfe539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7375614-d9fd-40aa-8066-9452aff5e1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62400dbc-a8f0-4198-9a50-54296b708228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc62a2-2c29-4843-9157-fa4ef56afad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cde28-85d5-4db0-8f79-b3ec71112e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denv",
   "language": "python",
   "name": "denv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
